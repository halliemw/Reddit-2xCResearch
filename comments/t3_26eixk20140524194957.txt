Well, I'll admit my bias because I am a psych major, but having said that empirical research follows pretty strict protocols in experiment design and application. That part of it is truly science by any definition. This isn't Freud sitting on his couch snorting cocaine telling you how all your problems are because of your sexual attraction to your mother/father.

In experimental psychology, you are testing independent (manipulated) and dependent (measured) variables. Basically, I change variable X and a resulting change in variable Y is noted. Where it gets sticky is determining causality versus correlation. Correlative results just mean X happens at a related frequency to Y. Whereas, casual results mean that X causes Y to happen.

In the research I was discussing, they were causal results because they made measurements in pre- and post-tests and determine a temporal order to the results. Basically, the participants views were tested, then manipulated, then tested again to show a difference between the two. What's more is these studies were replicated by multiple experimenters showing the same results. This lowers the possibility of a [Type I error](http://en.wikipedia.org/wiki/Type_I_and_type_II_errors), essentially the chance you falsely concluded there was an effect when there actually wasn't. Put another way, the mistake a jury makes when they send an innocent man to jail. All empirical research calculates the probability of making this type of error with the margins usually being 1-5%, meaning you are at least 95% positive of the result you found. Some even exceed that margin to only 0.1% or lower of being incorrect.

It's also important to remember that psychology also has many different fields within the topic. Some things are testable by experimental design and others are not because of ethics or just reproducibility.
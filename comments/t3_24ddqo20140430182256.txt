So do you think that all people sprout from the womb knowing what "rape" is, or are you under the impression that everyone somehow learns this from parents and schools? Because I can tell you that no family member or teacher *ever* told me what the legal definition of rape is. So I don't know why you're so hostile to the idea that young people should be taught what specifically is included in the definition of rape. A lot of people don't know that having sex with someone who is intoxicated is rape, and a lot of people don't understand the concept of getting affirmative consent before sex--plenty of people on this very website believe that it isn't rape if the victim didn't say no or fight back. So yes, education is needed on this topic. Ever man knows that physically forcing himself on a woman is rape, but many have never been told what else is included in the definition.